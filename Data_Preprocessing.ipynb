{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63983325",
   "metadata": {},
   "source": [
    "# üß© Car Insurance Claim Prediction ‚Äî Data Preprocessing & Feature Engineering\n",
    "\n",
    "This notebook preprocesses and encodes features for model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2255d0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Loaded Successfully\n",
      "Train shape: (58592, 44)\n",
      "Test shape: (39063, 43)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "# Load data\n",
    "base_path = \"car_insurance_data\"\n",
    "train_df = pd.read_csv(os.path.join(base_path, \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(base_path, \"test.csv\"))\n",
    "\n",
    "print(\"‚úÖ Data Loaded Successfully\")\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22566c1",
   "metadata": {},
   "source": [
    "## üß† Define Feature Categories\n",
    "We‚Äôll identify numerical and categorical features and separate the target variable `is_claim`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "070ca9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns: ['area_cluster', 'segment', 'model', 'fuel_type', 'max_torque', 'max_power', 'engine_type', 'is_esc', 'is_adjustable_steering', 'is_tpms', 'is_parking_sensors', 'is_parking_camera', 'rear_brakes_type', 'transmission_type', 'steering_type', 'is_front_fog_lights', 'is_rear_window_wiper', 'is_rear_window_washer', 'is_rear_window_defogger', 'is_brake_assist', 'is_power_door_locks', 'is_central_locking', 'is_power_steering', 'is_driver_seat_height_adjustable', 'is_day_night_rear_view_mirror', 'is_ecw', 'is_speed_alert']\n",
      "Numerical Columns: ['policy_tenure', 'age_of_car', 'age_of_policyholder', 'population_density', 'make', 'airbags', 'displacement', 'cylinder', 'gear_box', 'turning_radius', 'length', 'width', 'height', 'gross_weight', 'ncap_rating']\n"
     ]
    }
   ],
   "source": [
    "target_col = \"is_claim\"\n",
    "\n",
    "# Separate features and target\n",
    "X = train_df.drop(columns=[target_col, \"policy_id\"])\n",
    "y = train_df[target_col]\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = X.select_dtypes(exclude=[\"object\"]).columns.tolist()\n",
    "\n",
    "print(\"Categorical Columns:\", cat_cols)\n",
    "print(\"Numerical Columns:\", num_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80c24b2",
   "metadata": {},
   "source": [
    "## üß∞ Create Preprocessing Pipelines\n",
    "We‚Äôll use:\n",
    "- OneHotEncoder for categorical features\n",
    "- StandardScaler for numerical features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d6f2e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Preprocessing Pipeline Created\n"
     ]
    }
   ],
   "source": [
    "# Define transformers\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Combine into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Build preprocessing pipeline\n",
    "preprocess_pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "print(\"‚úÖ Preprocessing Pipeline Created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e6445",
   "metadata": {},
   "source": [
    "## üß™ Train‚ÄìValidation Split\n",
    "We‚Äôll hold out 20% of the data for validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bed4a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (46873, 42)\n",
      "Validation set: (11719, 42)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set:\", X_train.shape)\n",
    "print(\"Validation set:\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2153a2",
   "metadata": {},
   "source": [
    "## üîÑ Fit the Preprocessor on Training Data and Transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b7fa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data transformed successfully!\n",
      "Transformed training shape: (46873, 127)\n"
     ]
    }
   ],
   "source": [
    "# Fit and transform\n",
    "X_train_transformed = preprocess_pipeline.fit_transform(X_train)\n",
    "X_val_transformed = preprocess_pipeline.transform(X_val)\n",
    "\n",
    "print(\"‚úÖ Data transformed successfully!\")\n",
    "print(\"Transformed training shape:\", X_train_transformed.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f4a586",
   "metadata": {},
   "source": [
    "## üíæ Save the Preprocessor for Later Use\n",
    "This allows us to use the exact same transformations during model prediction (Streamlit app).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6afcdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Preprocessor pipeline saved as preprocessor.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the pipeline\n",
    "joblib.dump(preprocess_pipeline, \"preprocessor.pkl\")\n",
    "print(\"‚úÖ Preprocessor pipeline saved as preprocessor.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a818d5",
   "metadata": {},
   "source": [
    "### üîç Notes\n",
    "- The preprocessing pipeline ensures consistent encoding/scaling during model training and prediction.\n",
    "- The `preprocessor.pkl` will be loaded during deployment to preprocess user inputs.\n",
    "- Next step ‚û°Ô∏è **Model Training and Evaluation**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
